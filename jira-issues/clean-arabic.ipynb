{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jan  8 18:33:01 2019\n",
    "\n",
    "@author: sameamin\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_read_file(exten, file = None, column = None):\n",
    "    df = None\n",
    "    if exten == 'csv':\n",
    "        df = pd.read_csv(file, encoding = 'utf-8')\n",
    "    elif exten == 'excel':\n",
    "        df = pd.read_excel(file, column, encoding = 'utf-8')\n",
    "    return df\n",
    "\n",
    "\n",
    "def pipeline_remove_duplicates_empty(tokens):\n",
    "    tokens = list(filter(None, tokens))\n",
    "    tokens = list(set(tokens))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def pipeline_remove_specials_spaces(tokens):\n",
    "    tokens = [ re.sub(\"[^\\u0621-\\u06FF0-9/]+\", ' ', str(token)) for  token in tokens]\n",
    "    tokens = [re.sub(\"[Û­]+\", ' ', token) for  token in tokens]\n",
    "    tokens = [token.strip() for  token in tokens if len(token.strip()) > 1]\n",
    "    return tokens\n",
    "\n",
    "def pipeline_remove_abbrev(tokens):\n",
    "    # remove single chars\n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        token = ' '.join([w for w in str(token).split() if len(w) > 1])\n",
    "        tokens[i] = token\n",
    "\n",
    "    return tokens\n",
    "    \n",
    "def get_term_frequently(df):\n",
    "    df = df['Entity Name'].str.split(expand=True).stack().value_counts()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================================    \n",
    "# pipeline Start\n",
    "#=====================================================================\n",
    "source_file_name = 'data/3-jira-181-ar.csv'\n",
    "\n",
    "# read the file\n",
    "data = pipeline_read_file('csv', source_file_name)\n",
    "data.describe()\n",
    "\n",
    "tokens = data['Utterances'].values\n",
    "\n",
    "# special charachters and spaces\n",
    "tokens = pipeline_remove_specials_spaces(tokens)\n",
    "\n",
    "# remove abbreviations\n",
    "tokens = pipeline_remove_abbrev(tokens)\n",
    "\n",
    "# remove duplicates\n",
    "tokens = pipeline_remove_duplicates_empty(tokens)\n",
    "\n",
    "\n",
    "data = pd.DataFrame({'Utterances': tokens})\n",
    "data.describe()\n",
    "\n",
    "# check term frequently \n",
    "#df_term_freq = get_term_frequently(data)\n",
    "\n",
    "# write the file\n",
    "data.to_csv(\"data/4-jira-181-ar-cleaned.csv\", encoding='utf-8', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
